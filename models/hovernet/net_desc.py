
import os
from collections import OrderedDict

import torch
import torch.nn as nn
from torchvision.models.resnet import Bottleneck as ResNetBottleneck
from torchvision.models.resnet import ResNet

from .net_utils import DenseBlock, UpSample2x
from backpack import extend

class ResNetExt(ResNet):
    def _forward_impl(self, x, freeze):
        # See note [TorchScript super()]
        if self.training:
            x = self.conv1(x)
            x = self.bn1(x)
            x = self.relu(x)
            with torch.set_grad_enabled(not freeze):
                x1 = x = self.layer1(x)
                x2 = x = self.layer2(x)
                x3 = x = self.layer3(x)
                x4 = x = self.layer4(x)
        else:
            x = self.conv1(x)
            x = self.bn1(x)
            x = self.relu(x)
            x1 = x = self.layer1(x)
            x2 = x = self.layer2(x)
            x3 = x = self.layer3(x)
            x4 = x = self.layer4(x)
        return x1, x2, x3, x4

    def forward(self, x: torch.Tensor, freeze: bool = False) -> torch.Tensor:
        return self._forward_impl(x, freeze)

    @staticmethod
    def resnet50(num_input_channels, pretrained=None):
        model = ResNetExt(ResNetBottleneck, [3, 4, 6, 3])
        model.conv1 = nn.Conv2d(
            num_input_channels, 64, 7, stride=1, padding=3)
        if pretrained is not None and os.path.exists(pretrained):
            print(f"Loading: {pretrained}")
            pretrained = torch.load(pretrained)
            (
                missing_keys, unexpected_keys
            ) = model.load_state_dict(pretrained, strict=False)
        #elif not os.path.exists(pretrained):
        #    assert os.path.exists(pretrained), \
        #        f"Pretrained path is not valid: {pretrained}"
        return model

####
class HoVerNetExt(nn.Module):
    """Initialise HoVer-Net."""

    def __init__(
            self,
            num_types_source=None,
            num_types=None,
            freeze=False,
            pretrained_backbone=None,
            ):
        super().__init__()
        self.freeze = freeze
        self.num_types_source = num_types_source
        self.num_types = num_types
        self.output_ch = 3 if num_types is None else 4

        self.backbone = ResNetExt.resnet50(
            3, pretrained=pretrained_backbone)
        self.conv_bot = nn.Conv2d(
            2048, 1024, 1, stride=1, padding=0, bias=False)

        def create_decoder_branch(ksize):
            pad = ksize // 2
            module_list = [
                nn.Conv2d(1024, 256, ksize, stride=1, padding=pad, bias=False),
                DenseBlock(256, [1, ksize], [128, 32], 8, split=4),
                nn.Conv2d(512, 512, 1, stride=1, padding=0, bias=False),
            ]
            u3 = nn.Sequential(*module_list)

            module_list = [
                nn.Conv2d(512, 128, ksize, stride=1, padding=pad, bias=False),
                DenseBlock(128, [1, ksize], [128, 32], 4, split=4),
                nn.Conv2d(256, 256, 1, stride=1, padding=0, bias=False),
            ]
            u2 = nn.Sequential(*module_list)

            module_list = [
                nn.Conv2d(256, 64, ksize, stride=1, padding=pad, bias=False),
            ]
            u1 = nn.Sequential(*module_list)
            
            module_list = [
                nn.BatchNorm2d(64, eps=1e-5),
                nn.ReLU(inplace=True),
            ]
            u0 = nn.Sequential(*module_list)

            decoder = nn.Sequential(
                OrderedDict([("u3", u3), ("u2", u2), ("u1", u1), ("u0", u0)])
            )
            
            return decoder
                
        ksize = 3
        if num_types_source is None or num_types is None:
            raise Exception("Incorrect num_types!!!")
        
        self.decoder = nn.ModuleDict(
            OrderedDict(
                [
                    ("tp_feat", create_decoder_branch(ksize=ksize)),
                    ("np_feat", create_decoder_branch(ksize=ksize)),
                    ("hv", create_decoder_branch(ksize=ksize)),
                ]
            )
        )
            
        self.tp_layer = extend(nn.Conv2d(64, num_types, 1, stride=1, padding=0, bias=True))
        self.tp_layer_source = extend(nn.Conv2d(64, num_types_source, 1, stride=1, padding=0, bias=True))
        self.np_layer = extend(nn.Conv2d(64, 2, 1, stride=1, padding=0, bias=True))
        self.hv_layer = extend(nn.Conv2d(64, 2, 1, stride=1, padding=0, bias=True))

        self.upsample2x = UpSample2x()

    def forward(self, imgs):
        imgs = imgs / 255.0  # to 0-1 range to match XY

        d0, d1, d2, d3 = self.backbone(imgs, self.freeze)
        d3 = self.conv_bot(d3)
        d = [d0, d1, d2, d3]
        '''
        torch.Size([6, 256, 128, 128])
        torch.Size([6, 512, 64, 64])
        torch.Size([6, 1024, 32, 32])
        torch.Size([6, 1024, 16, 16])
        '''

        out_dict = OrderedDict()
        for branch_name, branch_desc in self.decoder.items():
        
            u3 = self.upsample2x(d[-1]) + d[-2]
            u3 = branch_desc[0](u3)

            u2 = self.upsample2x(u3) + d[-3]
            u2 = branch_desc[1](u2)

            u1 = self.upsample2x(u2) + d[-4]
            u1 = branch_desc[2](u1)

            u0 = branch_desc[3](u1)
            
            out_dict[branch_name] = u0

        out_dict['tp'] = self.tp_layer(out_dict['tp_feat'])
        out_dict['tp_source'] = self.tp_layer_source(out_dict['tp_feat'])
        out_dict['np'] = self.np_layer(out_dict['np_feat'])
        out_dict['hv'] = self.hv_layer(out_dict['hv'])
        
        return out_dict


####
def create_model(mode=None, **kwargs):
    return HoVerNetExt(**kwargs)
